{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6618f6fe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.2, random_state=42)\n",
    "y = y.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e114044f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_deriv(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def relu_deriv(z):\n",
    "    return (z > 0).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c374e74c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "input_size = 2\n",
    "hidden_size = 5\n",
    "output_size = 1\n",
    "\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "\n",
    "def train(X, y, epochs=1000, lr=0.01):\n",
    "    global W1, b1, W2, b2\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        Z1 = X.dot(W1) + b1\n",
    "        A1 = relu(Z1)\n",
    "        Z2 = A1.dot(W2) + b2\n",
    "        A2 = sigmoid(Z2)\n",
    "\n",
    "        # Loss (Binary Cross-Entropy)\n",
    "        m = y.shape[0]\n",
    "        loss = -np.mean(y * np.log(A2 + 1e-8) + (1 - y) * np.log(1 - A2 + 1e-8))\n",
    "\n",
    "        # Backpropagation\n",
    "        dZ2 = A2 - y\n",
    "        dW2 = A1.T.dot(dZ2) / m\n",
    "        db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "\n",
    "        dA1 = dZ2.dot(W2.T)\n",
    "        dZ1 = dA1 * relu_deriv(Z1)\n",
    "        dW1 = X.T.dot(dZ1) / m\n",
    "        db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "\n",
    "        # Update weights\n",
    "        W1 -= lr * dW1\n",
    "        b1 -= lr * db1\n",
    "        W2 -= lr * dW2\n",
    "        b2 -= lr * db2\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "\n",
    "train(X_train, y_train, epochs=1000, lr=0.1)\n",
    "\n",
    "\n",
    "def predict(X):\n",
    "    Z1 = X.dot(W1) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = A1.dot(W2) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    return (A2 > 0.5).astype(int)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
