{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8d4381",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a56bd8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 1: Hyperparameters and Setup ---\n",
    "# Define key training parameters\n",
    "BATCH_SIZE = 64\n",
    "LATENT_DIM = 100  # Dimension of the random noise vector\n",
    "IMAGE_SIZE = 28 * 28  # 28x28 pixels\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b9420",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d165e7c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a directory to save generated images\n",
    "if not os.path.exists('generated_images'):\n",
    "    os.makedirs('generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2be0a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 2: Define the Generator and Discriminator Networks ---\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    The Generator network takes a random noise vector as input and outputs a fake image.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(LATENT_DIM, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, IMAGE_SIZE),\n",
    "            nn.Tanh()  # Tanh activation to output values between -1 and 1\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        # The input z is a random noise vector\n",
    "        img = self.model(z)\n",
    "        # Reshape the output to be an image (1 channel, 28x28)\n",
    "        img = img.view(img.size(0), 1, 28, 28)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfae40d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    The Discriminator network takes an image as input and outputs a single value\n",
    "    representing the probability that the image is real.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(IMAGE_SIZE, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()  # Sigmoid activation to output a probability between 0 and 1\n",
    "        )\n",
    "    def forward(self, img):\n",
    "        # Flatten the image into a vector\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        # Pass the flattened image through the network\n",
    "        validity = self.model(img_flat)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa7d56",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 3: Load and Prepare Data ---\n",
    "# We use a transform that normalizes the images to the range [-1, 1]\n",
    "# to match the output of the Generator's Tanh activation.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49b5995",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Download and load the training data\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    transform=transform, \n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71811fdb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aecde22",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 4: Instantiate Models, Loss, and Optimizers ---\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf537f7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Binary cross-entropy loss is standard for GANs\n",
    "adversarial_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc1ede2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Optimizers for both networks. Adam is a good choice.\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=LEARNING_RATE)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3964a7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 5: Training Loop ---\n",
    "print(\"Starting GAN training...\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (imgs, _) in enumerate(train_loader):\n",
    "        # Create labels for real and fake images\n",
    "        real_labels = torch.ones(imgs.size(0), 1).to(device)\n",
    "        fake_labels = torch.zeros(imgs.size(0), 1).to(device)\n",
    "        \n",
    "        # --- Train the Discriminator ---\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # 1. Train with real images\n",
    "        real_imgs = imgs.to(device)\n",
    "        real_validity = discriminator(real_imgs)\n",
    "        d_loss_real = adversarial_loss(real_validity, real_labels)\n",
    "        \n",
    "        # 2. Train with fake images\n",
    "        z = torch.randn(imgs.size(0), LATENT_DIM).to(device)\n",
    "        fake_imgs = generator(z).detach() # Detach to prevent gradients from flowing to the Generator\n",
    "        fake_validity = discriminator(fake_imgs)\n",
    "        d_loss_fake = adversarial_loss(fake_validity, fake_labels)\n",
    "        \n",
    "        # Combine losses and update Discriminator\n",
    "        d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        \n",
    "        # --- Train the Generator ---\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Generate new fake images and calculate their validity\n",
    "        z = torch.randn(imgs.size(0), LATENT_DIM).to(device)\n",
    "        gen_imgs = generator(z)\n",
    "        gen_validity = discriminator(gen_imgs)\n",
    "\n",
    "        # Generator's loss is how well it fools the discriminator\n",
    "        g_loss = adversarial_loss(gen_validity, real_labels)\n",
    "        \n",
    "        # Update Generator\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "         \n",
    "        # Print progress\n",
    "        if i % 100 == 0:\n",
    "            print(f\"[Epoch {epoch+1}/{NUM_EPOCHS}] [Batch {i}/{len(train_loader)}] \"\n",
    "                  f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n",
    "        \n",
    "        # Save a sample of generated images after each epoch\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        z_sample = torch.randn(16, LATENT_DIM).to(device)\n",
    "        generated_sample = generator(z_sample)\n",
    "        save_image(generated_sample.data, f'generated_images/epoch_{epoch+1}.png', normalize=True)\n",
    "\n",
    "print(\"\\nGAN training finished.\")\n",
    "print(\"Generated images are saved in the 'generated_images' directory.\")\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
